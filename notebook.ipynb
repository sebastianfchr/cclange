{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# !!!!!! ATTENTION !!!!!!!!!\n",
    "# Use a venv for your jupyter-notebook, these installations will possibly be blocked\n",
    "%pip install -U requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Now we can start our docker for the \"service\" </u> \n",
    "To be honest, it's no real service. In reality I'd do this \n",
    "* in Kubernetes \n",
    "* or at least in docker-compose\n",
    "\n",
    "But to keep compatibility issues minimal, I'll strictly follow the exercise instructions, and just do a docker port-mapping to the host. (port 8123->8123).\n",
    "This will allow us to send requests to localhost:8123, and reach the server-api that's running on the docker. \n",
    "(Again, docker isn't the best way to do this. But we're talking fictional here)\n",
    "\n",
    "If notebook doesn't allow execution, you can always paste the commands below into your shell \n",
    "\n",
    "#### NOTE: It's much more reliable to paste these commands below into your shell directly. Don't trust Jupyter's execution: docker often doesn't have real rights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest: Pulling from sebastianfchr/appl_tfdocker\n",
      "Digest: sha256:d91e8857a1cc7a240a0e38f8362911f19b4f53d314303939b7510299d69ac366\n",
      "Status: Image is up to date for sebastianfchr/appl_tfdocker:latest\n",
      "docker.io/sebastianfchr/appl_tfdocker:latest\n",
      "5aad1df881ef2b87bcd127961f9493391892c303e611a5722a64f96605898a23\n"
     ]
    }
   ],
   "source": [
    "!docker pull sebastianfchr/appl_tfdocker:latest\n",
    "!docker run -d --gpus=all -v $(pwd):/code -p 8123:8123 -w /code sebastianfchr/appl_tfdocker:latest -- uvicorn serverapi:app --host 0.0.0.0 --port 8123\n",
    "# or if you use nerdctl:\n",
    "# nerdctl run -d --gpus=all -v $(pwd):/code -p 8123:8123 -w /code sebastianfchr/appl_tfdocker:latest -- uvicorn serverapi:app --host 0.0.0.0 --port 8123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Docker image\n",
    "Above, we use my custom cuda-tf-docker, that I use for such deployments, hosted on docker container-registry `docker.io/sebastianfchr/appl_tfdocker:latest`\n",
    "\n",
    "It takes some time to download, since it's *cuda enabled*. (It runs tf2.7, and the compatible cuda/cudnn version)\n",
    "\n",
    "Generally, I'm a fan of lightweigtht docker images. But in this application, where we leverage the full potential of GPU-tensorflow, we have to go with this one.\n",
    "\n",
    "\n",
    "\n",
    "### Sending requests\n",
    "\n",
    "All we need here, is the python-package \"requests\". I've created two endpoints on the server for\n",
    "* single sentence prediction\n",
    "* prediction of \"chunks\" of sentences \n",
    "\n",
    "### API\n",
    "I made two api-endpoints:\n",
    "* `server-url/predict_sentence_batch/` for the chunked version\n",
    "* `server-url/predict_sentence/` for the single version\n",
    "\n",
    "\n",
    "Since all the functionality is on the docker, we merely need to be able to send requests from pyton. Let's predict some sentiments then\n",
    "\n",
    "\n",
    "### <center> Important: Please make sure the docker is up and running. Its API-server takes a bit to load </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences and extractions: \n",
      " \n",
      "`going down the beautiful road, I met a horrible rabbit` extract: `positive`: \n",
      " ==>  beautiful\n",
      "\n",
      "`Sadly, the guys from HUK gave me the wrong weights, and I had to do specification training myself` extract: `negative`: \n",
      " ==>  sadly,\n",
      "\n",
      "`I really hope that despite the whole python compatibility hell you could happily execute everything until here` extract: `negative`: \n",
      " ==>  hell\n",
      "\n",
      "`I really hope that despite the whole python compatibility hell you could happily execute everything until here` extract: `positive`: \n",
      " ==>  hope\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# docker is reachable through this mapping\n",
    "url_batch = \"http://0.0.0.0:8123/predict_sentence_batch/\"\n",
    "\n",
    "sentences = [\n",
    "    \"going down the beautiful road, I met a horrible rabbit\",\n",
    "    \"Sadly, the guys from HUK gave me the wrong weights, and I had to do specification training myself\",\n",
    "    \"I really hope that despite the whole python compatibility hell you could happily execute everything until here\",\n",
    "    \"I really hope that despite the whole python compatibility hell you could happily execute everything until here\"\n",
    "]\n",
    "sentiments = [\n",
    "    \"positive\",\n",
    "    \"negative\",\n",
    "    \"negative\",\n",
    "    \"positive\"\n",
    "]\n",
    "\n",
    "# POST-data for the batched sentence\n",
    "data = {\"sentences\": [s for s in sentences], \"sentiments\": [s for s in sentiments]}\n",
    "response = requests.post(url_batch, json=data, headers={ 'Content-Type': 'application/json' })\n",
    "\n",
    "try:\n",
    "    extracted_sentence_fragments = response.json()['data']\n",
    "    print(\"sentences and extractions: \\n \")\n",
    "    for orig_sentence, sentiment, extr_fragment in zip (sentences, sentiments, extracted_sentence_fragments):\n",
    "        print(\"`{}` extract: `{}`: \\n ==> {}\\n\".format(orig_sentence, sentiment, extr_fragment))\n",
    "\n",
    "except: \n",
    "    print(\"response seems not to contian json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> What about speed?</u>\n",
    "\n",
    "Very good question: This is where it gets interesting. There are some relevant comparisons to make, since we're dealing with a server that takes requests, but we want efficient execution. First, some facts\n",
    "\n",
    "* GPUS are latency-hiding machines that want \"compute-bound\", parallelizable programs. ML: ðŸ‘Œ\n",
    "\n",
    "* GPUS have a n overhead for kernel-launches. So, launch the kernel on as many predictions (or as our GPU can)\n",
    "\n",
    "* Server requests have a round-trip time. That adds overhead to every request we make from the client\n",
    "\n",
    "* The above point means that we profit from chunking predictions within requests. But: Longer requests take a bit longer to send\n",
    "\n",
    "\n",
    "### A word about timing\n",
    "When we want to predict a number of sentences, \n",
    "we can investigate the time for the following modes.\n",
    "\n",
    "We differentiate between predictions that go through the API and those that don't:\n",
    "\n",
    "* single prediction request per API\n",
    "\n",
    "* chunked prediction requests per API\n",
    "\n",
    "* single direct prediction on tensorflow\n",
    "\n",
    "* single direct prediction on tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![title](\"./benchmarks.png\") -->\n",
    "\n",
    "<center><img src=\"./images/benchmarks.png\" width=80% height=80% /></center>\n",
    "\n",
    "### <u> Why this is relevant </u>\n",
    "\n",
    "First, these numbers aren't surprising. But they tell the MLOps engineer something very interesting:\n",
    "* requests are best chunked before being called by tensorflor (and cuda). I'd love to go into depth here\n",
    "* requests are best chunked before being sent to the API to avoid unnecessary round-trip times\n",
    "* to the above point, we see a small influence of message-size even if we make chunked requests (orange-right) \n",
    "\n",
    "###  What the developers can do\n",
    "\n",
    "In a real a real setting, there will be small requests per  client.\n",
    "\n",
    "However, the engineer can make some design-improvements in case our servers are under high load:\n",
    "* aggregate incoming API-requests from different clients (over a small timeframe)\n",
    "* predict them in a chunked fashion (fast!)\n",
    "* map each prediction back them to the client, and send them back\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Note: To run the rest, wee need to install requirements:<br> since the Challenge uses `tensorflow 2.7`, we must have a python-version between 2.6 and 2.9. Newer ones don't run this tf! \n",
    "\n",
    "you need to have the requirements)strict.txt installed to be exactly congruent with the setup demanded in the challenge (i.e. tf2.7 uses python3.6-3.9). If you encounter the exception above, try commenting it out and thus installing requirements_relaxed.txt. No Guarantee tho!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: tensorflow in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 2)) (2.19.0)\n",
      "Requirement already satisfied: numpy in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 3)) (2.1.3)\n",
      "Requirement already satisfied: setuptools in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 4)) (78.0.2)\n",
      "Requirement already satisfied: wheel in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 5)) (0.45.1)\n",
      "Requirement already satisfied: scikit-learn in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: transformers in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 7)) (4.50.0)\n",
      "Requirement already satisfied: protobuf in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 8)) (3.20.3)\n",
      "Requirement already satisfied: pytest in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 10)) (8.3.5)\n",
      "Requirement already satisfied: matplotlib in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from -r requirements/requirements_relaxed.txt (line 11)) (3.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from pandas->-r requirements/requirements_relaxed.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from pandas->-r requirements/requirements_relaxed.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from pandas->-r requirements/requirements_relaxed.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.9.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from scikit-learn->-r requirements/requirements_relaxed.txt (line 6)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from scikit-learn->-r requirements/requirements_relaxed.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from scikit-learn->-r requirements/requirements_relaxed.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: filelock in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from transformers->-r requirements/requirements_relaxed.txt (line 7)) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from transformers->-r requirements/requirements_relaxed.txt (line 7)) (0.29.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from transformers->-r requirements/requirements_relaxed.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from transformers->-r requirements/requirements_relaxed.txt (line 7)) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from transformers->-r requirements/requirements_relaxed.txt (line 7)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from transformers->-r requirements/requirements_relaxed.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from transformers->-r requirements/requirements_relaxed.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: iniconfig in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from pytest->-r requirements/requirements_relaxed.txt (line 10)) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from pytest->-r requirements/requirements_relaxed.txt (line 10)) (1.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from matplotlib->-r requirements/requirements_relaxed.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from matplotlib->-r requirements/requirements_relaxed.txt (line 11)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from matplotlib->-r requirements/requirements_relaxed.txt (line 11)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from matplotlib->-r requirements/requirements_relaxed.txt (line 11)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from matplotlib->-r requirements/requirements_relaxed.txt (line 11)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from matplotlib->-r requirements/requirements_relaxed.txt (line 11)) (3.2.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers->-r requirements/requirements_relaxed.txt (line 7)) (2025.3.0)\n",
      "Requirement already satisfied: rich in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (0.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/seb/python_venvs/general_venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->-r requirements/requirements_relaxed.txt (line 2)) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "(py_major, py_minor) = sys.version_info[0:2]\n",
    "\n",
    "if not (py_major != 2 and (6 <= py_minor <= 9)):\n",
    "    # raise Exception('Requires python 2.6-2.9, else you cannot run the code provided by HUK. '\n",
    "    # 'You can comment out this exception, and see whether it works with a newer Setup. \\n \\\n",
    "    #  The specification Tensorflow==2.7.0 is only compatible with 2.6-2.9. Similar things hold for transformers ')\n",
    "    %pip install -r requirements/requirements_relaxed.txt\n",
    "\n",
    "else: \n",
    "    %pip install -r requirements/requirements_strict.txt\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate your local benchmarks\n",
    "You can now generate your own benchmarks. The code below will generate a `benchmark_tf_and_api_calls.png` in this folder.\n",
    "\n",
    "\n",
    "### Note: Since the docker is running tf-gpu instance AND the benchmarking-script runs another one, this line will fail if your machine has less than ~4GB GPU vRam (~ 2GB reserved in docker, ~2 GB reserved here). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:05:58.744984: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-30 19:05:58.753686: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743354358.763692   72815 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743354358.767071   72815 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743354358.774991   72815 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743354358.775004   72815 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743354358.775006   72815 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743354358.775007   72815 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 19:05:58.777905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "I0000 00:00:1743354360.986415   72815 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1396 MB memory:  -> device: 0, name: NVIDIA GeForce MX550, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "All model checkpoint layers were used when initializing TFRobertaModel.\n",
      "\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at /home/seb/Desktop/CodingChallenge_MLE/roberta/config/pretrained-roberta-base.h5.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='0.0.0.0', port=8123): Max retries exceeded with url: /predict_sentence_batch/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f55d6995070>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/connection.py:445\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1331\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1091\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1094\u001b[39m \n\u001b[32m   1095\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1035\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1035\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/connection.py:276\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    278\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/connection.py:213\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    217\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPConnection object at 0x7f55d6995070>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='0.0.0.0', port=8123): Max retries exceeded with url: /predict_sentence_batch/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f55d6995070>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbenchmark\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CodingChallenge_MLE/benchmark.py:63\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# make one dummy request to warm up tensorflow cuda-kernel launch (I'm not joking!)\u001b[39;00m\n\u001b[32m     61\u001b[39m single_bare_requests(test[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m1\u001b[39m], test[\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m][:\u001b[32m1\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m ys_server_single = [\u001b[43msingle_server_requests\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentiment\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[32m     64\u001b[39m ys_server_chunked = [chunked_server_requests(test[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m][:i], test[\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m][:i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[32m     65\u001b[39m ys_bare_single = [single_bare_requests(test[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m][:i], test[\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m][:i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m xs]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/CodingChallenge_MLE/benchmark.py:29\u001b[39m, in \u001b[36msingle_server_requests\u001b[39m\u001b[34m(sentences, sentiments)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence, sentiment \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sentences, sentiments):\n\u001b[32m     28\u001b[39m     data = {\u001b[33m\"\u001b[39m\u001b[33msentences\u001b[39m\u001b[33m\"\u001b[39m: [sentence], \u001b[33m\"\u001b[39m\u001b[33msentiments\u001b[39m\u001b[33m\"\u001b[39m: [sentiment]}\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m time.time()-start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/python_venvs/general_venv/lib/python3.12/site-packages/requests/adapters.py:700\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    696\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    697\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m    698\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m--> \u001b[39m\u001b[32m700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    703\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n",
      "\u001b[31mConnectionError\u001b[39m: HTTPConnectionPool(host='0.0.0.0', port=8123): Max retries exceeded with url: /predict_sentence_batch/ (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f55d6995070>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "import benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python tests\n",
    "\n",
    "\n",
    "### Note: Since the docker is running tf-gpu instance AND the testing runs another one, this line will fail if your machine has less than ~4GB GPU vRam (~ 2GB reserved in docker, ~2 GB reserved here). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.3, pytest-8.3.5, pluggy-1.5.0\n",
      "rootdir: /home/seb/Desktop/CodingChallenge_MLE\n",
      "collected 3 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "test_components.py \u001b[31mF\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[31m                                                   [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m________ TestClassPredictor.test_batched_sentence_extraction_vs_manual _________\u001b[0m\n",
      "\n",
      "self = <test_components.TestClassPredictor object at 0x7295e1e880b0>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_batched_sentence_extraction_vs_manual\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\" Sanity check for RobertaPredictor.predict_sentence_batch(). Tests whether it produces\u001b[39;49;00m\n",
      "    \u001b[33m    the same sentence-fragment as manual tokenization, prediction, and decoding \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        num_elements_tested = \u001b[94m10\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "        tokenizer = tokenizers.ByteLevelBPETokenizer.from_file(\u001b[33m'\u001b[39;49;00m\u001b[33m./roberta/config/vocab-roberta-base.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m./roberta/config/merges-roberta-base.txt\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lowercase=\u001b[94mTrue\u001b[39;49;00m, add_prefix_space=\u001b[94mTrue\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      ">       rp = RobertaPredictor(MAX_LEN, \u001b[33m'\u001b[39;49;00m\u001b[33mv0-roberta-0.h5\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, tokenizer)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtest_components.py\u001b[0m:18: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mroberta/predict.py\u001b[0m:22: in __init__\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.model = build_model(\u001b[96mself\u001b[39;49;00m.max_len_tokens)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mroberta/models.py\u001b[0m:62: in build_model\n",
      "    \u001b[0mbert_model = TFRobertaModel.from_pretrained(os.path.join(package_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mconfig\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpretrained-roberta-base.h5\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), config=config)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\u001b[0m:2977: in from_pretrained\n",
      "    \u001b[0mmodel.build_in_name_scope()  \u001b[90m# build the network with dummy inputs\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\u001b[0m:1197: in build_in_name_scope\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.build(input_shape=\u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m:1060: in build\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.roberta.build(\u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m:865: in build\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.encoder.build(\u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m:660: in build\n",
      "    \u001b[0mlayer.build(\u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m:575: in build\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.intermediate.build(\u001b[94mNone\u001b[39;49;00m)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\u001b[0m:446: in build\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.dense.build([\u001b[94mNone\u001b[39;49;00m, \u001b[94mNone\u001b[39;49;00m, \u001b[96mself\u001b[39;49;00m.config.hidden_size])\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/layers/core/dense.py\u001b[0m:154: in build\n",
      "    \u001b[0m\u001b[96mself\u001b[39;49;00m.kernel = \u001b[96mself\u001b[39;49;00m.add_weight(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\u001b[0m:705: in add_weight\n",
      "    \u001b[0mvariable = \u001b[96mself\u001b[39;49;00m._add_variable_with_custom_getter(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/tensorflow/python/trackable/base.py\u001b[0m:492: in _add_variable_with_custom_getter\n",
      "    \u001b[0mnew_variable = getter(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer_utils.py\u001b[0m:137: in make_variable\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m tf1.Variable(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m:153: in error_handler\n",
      "    \u001b[0m\u001b[94mraise\u001b[39;49;00m e.with_traceback(filtered_tb) \u001b[94mfrom\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/initializers/initializers.py\u001b[0m:525: in __call__\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._random_generator.truncated_normal(\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <tf_keras.src.backend.RandomGenerator object at 0x7295266ef050>\n",
      "shape = [768, 3072], mean = 0.0, stddev = 0.02, dtype = tf.float32, nonce = None\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtruncated_normal\u001b[39;49;00m(\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m, shape, mean=\u001b[94m0.0\u001b[39;49;00m, stddev=\u001b[94m1.0\u001b[39;49;00m, dtype=\u001b[94mNone\u001b[39;49;00m, nonce=\u001b[94mNone\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    ):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Produce random number based on the truncated normal distribution.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Args:\u001b[39;49;00m\n",
      "    \u001b[33m      shape: The shape of the random values to generate.\u001b[39;49;00m\n",
      "    \u001b[33m      mean: Floats, default to 0. Mean of the random values to generate.\u001b[39;49;00m\n",
      "    \u001b[33m      stddev: Floats, default to 1. Standard deviation of the random values\u001b[39;49;00m\n",
      "    \u001b[33m        to generate.\u001b[39;49;00m\n",
      "    \u001b[33m      dtype: Optional dtype of the tensor. Only floating point types are\u001b[39;49;00m\n",
      "    \u001b[33m        supported. If not specified, `tf.keras.backend.floatx()` is used,\u001b[39;49;00m\n",
      "    \u001b[33m        which default to `float32` unless you configured it otherwise (via\u001b[39;49;00m\n",
      "    \u001b[33m        `tf.keras.backend.set_floatx(float_dtype)`)\u001b[39;49;00m\n",
      "    \u001b[33m      nonce: Optional integer scalar, that will be folded into the seed in\u001b[39;49;00m\n",
      "    \u001b[33m        the stateless mode.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m._maybe_init()\u001b[90m\u001b[39;49;00m\n",
      "        dtype = dtype \u001b[95mor\u001b[39;49;00m floatx()\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._rng_type == \u001b[96mself\u001b[39;49;00m.RNG_STATEFUL:\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mreturn\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._generator.truncated_normal(\u001b[90m\u001b[39;49;00m\n",
      "                shape=shape, mean=mean, stddev=stddev, dtype=dtype\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94melif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m._rng_type == \u001b[96mself\u001b[39;49;00m.RNG_STATELESS:\u001b[90m\u001b[39;49;00m\n",
      "            seed = \u001b[96mself\u001b[39;49;00m.make_seed_for_stateless_op()\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[94mif\u001b[39;49;00m nonce:\u001b[90m\u001b[39;49;00m\n",
      "                seed = tf.random.experimental.stateless_fold_in(seed, nonce)\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mreturn\u001b[39;49;00m tf.random.stateless_truncated_normal(\u001b[90m\u001b[39;49;00m\n",
      "                shape=shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed\u001b[90m\u001b[39;49;00m\n",
      "            )\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name:\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m../../python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/backend.py\u001b[0m:2144: ResourceExhaustedError\n",
      "----------------------------- Captured stderr call -----------------------------\n",
      "I0000 00:00:1743354510.803338   73494 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 157 MB memory:  -> device: 0, name: NVIDIA GeForce MX550, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1743354510.813585   73494 cuda_executor.cc:479] failed to allocate 157.50MiB (165150720 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1743354510.970903   73494 cuda_executor.cc:479] failed to allocate 15.75MiB (16515072 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1743354510.970974   73494 cuda_executor.cc:479] failed to allocate 14.17MiB (14863616 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1743354510.970988   73494 cuda_executor.cc:479] failed to allocate 12.76MiB (13377280 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-03-30 19:08:40.971573: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.00MiB (rounded to 9437184)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-03-30 19:08:40.971619: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1058] BFCAllocator dump for GPU_0_bfc\n",
      "2025-03-30 19:08:40.971625: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (256): \tTotal Chunks: 7, Chunks in use: 7. 1.8KiB allocated for chunks. 1.8KiB in use in bin. 48B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971629: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971637: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971642: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2048): \tTotal Chunks: 42, Chunks in use: 42. 126.0KiB allocated for chunks. 126.0KiB in use in bin. 126.0KiB client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971644: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971648: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8192): \tTotal Chunks: 4, Chunks in use: 4. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971650: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971653: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971655: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971658: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971661: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971663: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971675: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971679: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2097152): \tTotal Chunks: 22, Chunks in use: 19. 49.33MiB allocated for chunks. 42.75MiB in use in bin. 42.75MiB client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971683: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971686: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8388608): \tTotal Chunks: 10, Chunks in use: 10. 99.23MiB allocated for chunks. 99.23MiB in use in bin. 90.00MiB client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971688: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971690: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971692: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971695: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971697: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:08:40.971699: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1081] Bin for 9.00MiB was 8.00MiB, Chunk State: \n",
      "2025-03-30 19:08:40.971701: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 148635648\n",
      "2025-03-30 19:08:40.971706: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2000000 of size 256 next 1\n",
      "2025-03-30 19:08:40.971708: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2000100 of size 1280 next 2\n",
      "2025-03-30 19:08:40.971710: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2000600 of size 256 next 3\n",
      "2025-03-30 19:08:40.971711: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2000700 of size 256 next 4\n",
      "2025-03-30 19:08:40.971713: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2000800 of size 256 next 6\n",
      "2025-03-30 19:08:40.971715: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2000900 of size 3072 next 7\n",
      "2025-03-30 19:08:40.971717: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2001500 of size 4715776 next 8\n",
      "2025-03-30 19:08:40.971719: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2480a00 of size 2359296 next 9\n",
      "2025-03-30 19:08:40.971721: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c0a00 of size 3072 next 10\n",
      "2025-03-30 19:08:40.971722: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c1600 of size 3072 next 5\n",
      "2025-03-30 19:08:40.971724: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c2200 of size 3072 next 13\n",
      "2025-03-30 19:08:40.971726: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c2e00 of size 256 next 16\n",
      "2025-03-30 19:08:40.971727: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c2f00 of size 3072 next 18\n",
      "2025-03-30 19:08:40.971729: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c3b00 of size 3072 next 19\n",
      "2025-03-30 19:08:40.971733: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c4700 of size 12288 next 22\n",
      "2025-03-30 19:08:40.971735: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c7700 of size 3072 next 25\n",
      "2025-03-30 19:08:40.971737: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c8300 of size 3072 next 20\n",
      "2025-03-30 19:08:40.971738: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c8f00 of size 3072 next 21\n",
      "2025-03-30 19:08:40.971740: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26c9b00 of size 3072 next 27\n",
      "2025-03-30 19:08:40.971742: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26ca700 of size 3072 next 28\n",
      "2025-03-30 19:08:40.971744: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26cb300 of size 3072 next 30\n",
      "2025-03-30 19:08:40.971746: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26cbf00 of size 3072 next 32\n",
      "2025-03-30 19:08:40.971747: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26ccb00 of size 3072 next 34\n",
      "2025-03-30 19:08:40.971749: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26cd700 of size 3072 next 36\n",
      "2025-03-30 19:08:40.971751: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26ce300 of size 12288 next 37\n",
      "2025-03-30 19:08:40.971753: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d1300 of size 3072 next 38\n",
      "2025-03-30 19:08:40.971754: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d1f00 of size 3072 next 41\n",
      "2025-03-30 19:08:40.971756: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d2b00 of size 3072 next 43\n",
      "2025-03-30 19:08:40.971758: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d3700 of size 3072 next 44\n",
      "2025-03-30 19:08:40.971760: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d4300 of size 3072 next 45\n",
      "2025-03-30 19:08:40.971766: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d4f00 of size 3072 next 47\n",
      "2025-03-30 19:08:40.971768: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d5b00 of size 3072 next 49\n",
      "2025-03-30 19:08:40.971769: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d6700 of size 3072 next 51\n",
      "2025-03-30 19:08:40.971771: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d7300 of size 3072 next 52\n",
      "2025-03-30 19:08:40.971773: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26d7f00 of size 12288 next 53\n",
      "2025-03-30 19:08:40.971774: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26daf00 of size 3072 next 54\n",
      "2025-03-30 19:08:40.971776: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26dbb00 of size 3072 next 57\n",
      "2025-03-30 19:08:40.971778: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26dc700 of size 3072 next 59\n",
      "2025-03-30 19:08:40.971779: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26dd300 of size 3072 next 60\n",
      "2025-03-30 19:08:40.971781: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26ddf00 of size 3072 next 61\n",
      "2025-03-30 19:08:40.971782: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26deb00 of size 3072 next 63\n",
      "2025-03-30 19:08:40.971784: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26df700 of size 3072 next 65\n",
      "2025-03-30 19:08:40.971786: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e0300 of size 3072 next 67\n",
      "2025-03-30 19:08:40.971787: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e0f00 of size 3072 next 68\n",
      "2025-03-30 19:08:40.971789: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e1b00 of size 12288 next 69\n",
      "2025-03-30 19:08:40.971792: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e4b00 of size 3072 next 70\n",
      "2025-03-30 19:08:40.971794: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e5700 of size 3072 next 73\n",
      "2025-03-30 19:08:40.971797: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e6300 of size 3072 next 74\n",
      "2025-03-30 19:08:40.971799: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e6f00 of size 3072 next 75\n",
      "2025-03-30 19:08:40.971801: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e7b00 of size 3072 next 76\n",
      "2025-03-30 19:08:40.971802: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e8700 of size 3072 next 78\n",
      "2025-03-30 19:08:40.971804: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e9300 of size 3072 next 80\n",
      "2025-03-30 19:08:40.971805: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26e9f00 of size 3072 next 82\n",
      "2025-03-30 19:08:40.971807: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26eab00 of size 3072 next 83\n",
      "2025-03-30 19:08:40.971809: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26eb700 of size 256 next 84\n",
      "2025-03-30 19:08:40.971810: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c26eb800 of size 256 next 85\n",
      "2025-03-30 19:08:40.971812: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7293c26eb900 of size 2183424 next 11\n",
      "2025-03-30 19:08:40.971814: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2900a00 of size 2359296 next 12\n",
      "2025-03-30 19:08:40.971815: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7293c2b40a00 of size 2359296 next 14\n",
      "2025-03-30 19:08:40.971817: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2d80a00 of size 2359296 next 15\n",
      "2025-03-30 19:08:40.971819: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c2fc0a00 of size 2359296 next 17\n",
      "2025-03-30 19:08:40.971820: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c3200a00 of size 2359296 next 29\n",
      "2025-03-30 19:08:40.971822: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c3440a00 of size 2359296 next 31\n",
      "2025-03-30 19:08:40.971824: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c3680a00 of size 2359296 next 33\n",
      "2025-03-30 19:08:40.971825: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c38c0a00 of size 2359296 next 35\n",
      "2025-03-30 19:08:40.971827: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c3b00a00 of size 2359296 next 46\n",
      "2025-03-30 19:08:40.971828: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c3d40a00 of size 2359296 next 48\n",
      "2025-03-30 19:08:40.971830: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c3f80a00 of size 2359296 next 50\n",
      "2025-03-30 19:08:40.971832: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7293c41c0a00 of size 2359296 next 23\n",
      "2025-03-30 19:08:40.971833: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c4400a00 of size 9437184 next 24\n",
      "2025-03-30 19:08:40.971836: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c4d00a00 of size 9437184 next 26\n",
      "2025-03-30 19:08:40.971838: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c5600a00 of size 2359296 next 62\n",
      "2025-03-30 19:08:40.971840: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c5840a00 of size 2359296 next 64\n",
      "2025-03-30 19:08:40.971841: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c5a80a00 of size 2359296 next 66\n",
      "2025-03-30 19:08:40.971843: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c5cc0a00 of size 2359296 next 39\n",
      "2025-03-30 19:08:40.971850: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c5f00a00 of size 9437184 next 40\n",
      "2025-03-30 19:08:40.971851: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c6800a00 of size 9437184 next 42\n",
      "2025-03-30 19:08:40.971853: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c7100a00 of size 2359296 next 77\n",
      "2025-03-30 19:08:40.971855: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c7340a00 of size 2359296 next 79\n",
      "2025-03-30 19:08:40.971856: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c7580a00 of size 2359296 next 81\n",
      "2025-03-30 19:08:40.971858: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c77c0a00 of size 2359296 next 55\n",
      "2025-03-30 19:08:40.971860: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c7a00a00 of size 9437184 next 56\n",
      "2025-03-30 19:08:40.971861: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c8300a00 of size 9437184 next 58\n",
      "2025-03-30 19:08:40.971863: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c8c00a00 of size 9437184 next 71\n",
      "2025-03-30 19:08:40.971865: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c9500a00 of size 9437184 next 72\n",
      "2025-03-30 19:08:40.971867: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293c9e00a00 of size 16512512 next 18446744073709551615\n",
      "2025-03-30 19:08:40.971868: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 12039680\n",
      "2025-03-30 19:08:40.971870: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7293cb200000 of size 12039680 next 18446744073709551615\n",
      "2025-03-30 19:08:40.971872: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119]      Summary of in-use Chunks by size: \n",
      "2025-03-30 19:08:40.971875: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 7 Chunks of size 256 totalling 1.8KiB\n",
      "2025-03-30 19:08:40.971877: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-03-30 19:08:40.971879: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 42 Chunks of size 3072 totalling 126.0KiB\n",
      "2025-03-30 19:08:40.971882: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 4 Chunks of size 12288 totalling 48.0KiB\n",
      "2025-03-30 19:08:40.971884: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 19 Chunks of size 2359296 totalling 42.75MiB\n",
      "2025-03-30 19:08:40.971886: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 4715776 totalling 4.50MiB\n",
      "2025-03-30 19:08:40.971888: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 8 Chunks of size 9437184 totalling 72.00MiB\n",
      "2025-03-30 19:08:40.971891: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 12039680 totalling 11.48MiB\n",
      "2025-03-30 19:08:40.971893: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 16512512 totalling 15.75MiB\n",
      "2025-03-30 19:08:40.971895: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1126] Sum Total of in-use chunks: 146.65MiB\n",
      "2025-03-30 19:08:40.971897: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1128] Total bytes in pool: 160675328 memory_limit_: 165150720 available bytes: 4475392 curr_region_allocation_bytes_: 660602880\n",
      "2025-03-30 19:08:40.971901: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1133] Stats: \n",
      "Limit:                       165150720\n",
      "InUse:                       153773312\n",
      "MaxInUse:                    153773312\n",
      "NumAllocs:                         196\n",
      "MaxAllocSize:                 16512512\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-30 19:08:40.971905: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *****************************************************************************************xxx*******x\n",
      "2025-03-30 19:08:40.971914: W tensorflow/core/framework/op_kernel.cc:1844] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2025-03-30 19:08:40.971933: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "../../python_venvs/general_venv/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:91\n",
      "  /home/seb/python_venvs/general_venv/lib/python3.12/site-packages/google/protobuf/internal/well_known_types.py:91: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "    _EPOCH_DATETIME_NAIVE = datetime.datetime.utcfromtimestamp(0)\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m test_components.py::\u001b[1mTestClassPredictor::test_batched_sentence_extraction_vs_manual\u001b[0m - tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_...\n",
      "\u001b[31m=================== \u001b[31m\u001b[1m1 failed\u001b[0m, \u001b[32m2 passed\u001b[0m, \u001b[33m1 warning\u001b[0m\u001b[31m in 12.98s\u001b[0m\u001b[31m ====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# To run all my tests\n",
    "# now, let's hope pytest selects the correct version that you're using in this notebook\n",
    "!pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are two main things that I identified as testworthy\n",
    "* correct tf-model interfacing in deployment\n",
    "* correct API server behavior\n",
    "\n",
    "#### <u>1. Check for correct tf-model-interfacing and text-prediction: <br></u> `test_batched_sentence_extraction_vs_manual`\n",
    "The text goes through quite some processing before the data gets into the kernel-call. \n",
    "* Text preparation \n",
    "* Text tokenization \n",
    "* Masking\n",
    "* Prediction, tokenized output\n",
    "* Decoding of predicted tokens. This gives us the sentence-fragment\n",
    "\n",
    "Fully automating into the above used functions to\n",
    "\n",
    "`predict_sentence_batch(<<sentence>>, <<sentiment>>)` \n",
    "\n",
    "`predict_sentence(<<sentence>>, <<sentiment>>)` \n",
    "\n",
    "means to go through all the above stages. To test this code, I compared\n",
    "* a completely manually written version \n",
    "* the automatized versions above\n",
    "\n",
    "\n",
    "#### <u> 2. Check for correct API Behavior: </u> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u> Train your own weights </u> \n",
    "\n",
    "After refractoring a lot, I only left the training-loop itself intact. Check out the following program to train your own weights. \n",
    "\n",
    "\n",
    "I found that this line does not run unless you comply with requirements_strict. <br>It looks like huggingface's transformers relied on tf-calls that changed in later versions (that is, later than about tf2.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:07:41.050326: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-30 19:07:41.058923: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743354461.068529   73402 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743354461.071742   73402 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743354461.080146   73402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743354461.080162   73402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743354461.080163   73402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743354461.080165   73402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 19:07:41.082433: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "#########################\n",
      "### FOLD 1\n",
      "#########################\n",
      "I0000 00:00:1743354465.498210   73402 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 157 MB memory:  -> device: 0, name: NVIDIA GeForce MX550, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1743354465.506888   73402 cuda_executor.cc:479] failed to allocate 157.50MiB (165150720 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1743354465.653060   73402 cuda_executor.cc:479] failed to allocate 15.75MiB (16515072 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1743354465.653102   73402 cuda_executor.cc:479] failed to allocate 14.17MiB (14863616 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "I0000 00:00:1743354465.653115   73402 cuda_executor.cc:479] failed to allocate 12.76MiB (13377280 bytes) from device: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-03-30 19:07:55.653656: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.00MiB (rounded to 9437184)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2025-03-30 19:07:55.653729: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1058] BFCAllocator dump for GPU_0_bfc\n",
      "2025-03-30 19:07:55.653748: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (256): \tTotal Chunks: 7, Chunks in use: 7. 1.8KiB allocated for chunks. 1.8KiB in use in bin. 48B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653760: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653771: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653788: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2048): \tTotal Chunks: 42, Chunks in use: 42. 126.0KiB allocated for chunks. 126.0KiB in use in bin. 126.0KiB client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653798: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653810: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8192): \tTotal Chunks: 4, Chunks in use: 4. 48.0KiB allocated for chunks. 48.0KiB in use in bin. 48.0KiB client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653824: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653861: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653876: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653893: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653910: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653923: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653940: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653963: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (2097152): \tTotal Chunks: 22, Chunks in use: 19. 49.33MiB allocated for chunks. 42.75MiB in use in bin. 42.75MiB client-requested in use in bin.\n",
      "2025-03-30 19:07:55.653990: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (4194304): \tTotal Chunks: 1, Chunks in use: 1. 4.50MiB allocated for chunks. 4.50MiB in use in bin. 2.25MiB client-requested in use in bin.\n",
      "2025-03-30 19:07:55.654010: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (8388608): \tTotal Chunks: 10, Chunks in use: 10. 99.23MiB allocated for chunks. 99.23MiB in use in bin. 90.00MiB client-requested in use in bin.\n",
      "2025-03-30 19:07:55.654024: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.654054: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.654067: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.654082: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.654096: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1065] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2025-03-30 19:07:55.654117: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1081] Bin for 9.00MiB was 8.00MiB, Chunk State: \n",
      "2025-03-30 19:07:55.654128: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 148635648\n",
      "2025-03-30 19:07:55.654141: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6000000 of size 256 next 1\n",
      "2025-03-30 19:07:55.654149: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6000100 of size 1280 next 2\n",
      "2025-03-30 19:07:55.654157: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6000600 of size 256 next 3\n",
      "2025-03-30 19:07:55.654163: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6000700 of size 256 next 4\n",
      "2025-03-30 19:07:55.654173: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6000800 of size 256 next 6\n",
      "2025-03-30 19:07:55.654184: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6000900 of size 3072 next 7\n",
      "2025-03-30 19:07:55.654191: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6001500 of size 4715776 next 8\n",
      "2025-03-30 19:07:55.654202: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6480a00 of size 2359296 next 9\n",
      "2025-03-30 19:07:55.654209: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c0a00 of size 3072 next 10\n",
      "2025-03-30 19:07:55.654218: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c1600 of size 3072 next 5\n",
      "2025-03-30 19:07:55.654232: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c2200 of size 3072 next 13\n",
      "2025-03-30 19:07:55.654242: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c2e00 of size 256 next 16\n",
      "2025-03-30 19:07:55.654251: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c2f00 of size 3072 next 18\n",
      "2025-03-30 19:07:55.654261: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c3b00 of size 3072 next 19\n",
      "2025-03-30 19:07:55.654268: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c4700 of size 12288 next 22\n",
      "2025-03-30 19:07:55.654274: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c7700 of size 3072 next 25\n",
      "2025-03-30 19:07:55.654280: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c8300 of size 3072 next 20\n",
      "2025-03-30 19:07:55.654289: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c8f00 of size 3072 next 21\n",
      "2025-03-30 19:07:55.654298: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66c9b00 of size 3072 next 27\n",
      "2025-03-30 19:07:55.654307: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66ca700 of size 3072 next 28\n",
      "2025-03-30 19:07:55.654316: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66cb300 of size 3072 next 30\n",
      "2025-03-30 19:07:55.654326: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66cbf00 of size 3072 next 32\n",
      "2025-03-30 19:07:55.654337: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66ccb00 of size 3072 next 34\n",
      "2025-03-30 19:07:55.654370: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66cd700 of size 3072 next 36\n",
      "2025-03-30 19:07:55.654380: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66ce300 of size 12288 next 37\n",
      "2025-03-30 19:07:55.654389: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d1300 of size 3072 next 38\n",
      "2025-03-30 19:07:55.654399: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d1f00 of size 3072 next 41\n",
      "2025-03-30 19:07:55.654407: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d2b00 of size 3072 next 43\n",
      "2025-03-30 19:07:55.654415: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d3700 of size 3072 next 44\n",
      "2025-03-30 19:07:55.654439: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d4300 of size 3072 next 45\n",
      "2025-03-30 19:07:55.654445: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d4f00 of size 3072 next 47\n",
      "2025-03-30 19:07:55.654452: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d5b00 of size 3072 next 49\n",
      "2025-03-30 19:07:55.654459: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d6700 of size 3072 next 51\n",
      "2025-03-30 19:07:55.654465: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d7300 of size 3072 next 52\n",
      "2025-03-30 19:07:55.654471: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66d7f00 of size 12288 next 53\n",
      "2025-03-30 19:07:55.654477: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66daf00 of size 3072 next 54\n",
      "2025-03-30 19:07:55.654483: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66dbb00 of size 3072 next 57\n",
      "2025-03-30 19:07:55.654489: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66dc700 of size 3072 next 59\n",
      "2025-03-30 19:07:55.654496: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66dd300 of size 3072 next 60\n",
      "2025-03-30 19:07:55.654501: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66ddf00 of size 3072 next 61\n",
      "2025-03-30 19:07:55.654507: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66deb00 of size 3072 next 63\n",
      "2025-03-30 19:07:55.654514: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66df700 of size 3072 next 65\n",
      "2025-03-30 19:07:55.654520: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e0300 of size 3072 next 67\n",
      "2025-03-30 19:07:55.654526: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e0f00 of size 3072 next 68\n",
      "2025-03-30 19:07:55.654533: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e1b00 of size 12288 next 69\n",
      "2025-03-30 19:07:55.654542: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e4b00 of size 3072 next 70\n",
      "2025-03-30 19:07:55.654551: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e5700 of size 3072 next 73\n",
      "2025-03-30 19:07:55.654560: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e6300 of size 3072 next 74\n",
      "2025-03-30 19:07:55.654566: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e6f00 of size 3072 next 75\n",
      "2025-03-30 19:07:55.654575: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e7b00 of size 3072 next 76\n",
      "2025-03-30 19:07:55.654584: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e8700 of size 3072 next 78\n",
      "2025-03-30 19:07:55.654592: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e9300 of size 3072 next 80\n",
      "2025-03-30 19:07:55.654601: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66e9f00 of size 3072 next 82\n",
      "2025-03-30 19:07:55.654611: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66eab00 of size 3072 next 83\n",
      "2025-03-30 19:07:55.654620: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66eb700 of size 256 next 84\n",
      "2025-03-30 19:07:55.654629: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a66eb800 of size 256 next 85\n",
      "2025-03-30 19:07:55.654638: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7883a66eb900 of size 2183424 next 11\n",
      "2025-03-30 19:07:55.654646: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6900a00 of size 2359296 next 12\n",
      "2025-03-30 19:07:55.654654: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7883a6b40a00 of size 2359296 next 14\n",
      "2025-03-30 19:07:55.654662: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6d80a00 of size 2359296 next 15\n",
      "2025-03-30 19:07:55.654671: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a6fc0a00 of size 2359296 next 17\n",
      "2025-03-30 19:07:55.654679: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a7200a00 of size 2359296 next 29\n",
      "2025-03-30 19:07:55.654687: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a7440a00 of size 2359296 next 31\n",
      "2025-03-30 19:07:55.654695: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a7680a00 of size 2359296 next 33\n",
      "2025-03-30 19:07:55.654702: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a78c0a00 of size 2359296 next 35\n",
      "2025-03-30 19:07:55.654710: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a7b00a00 of size 2359296 next 46\n",
      "2025-03-30 19:07:55.654718: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a7d40a00 of size 2359296 next 48\n",
      "2025-03-30 19:07:55.654726: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a7f80a00 of size 2359296 next 50\n",
      "2025-03-30 19:07:55.654734: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] Free  at 7883a81c0a00 of size 2359296 next 23\n",
      "2025-03-30 19:07:55.654742: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a8400a00 of size 9437184 next 24\n",
      "2025-03-30 19:07:55.654751: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a8d00a00 of size 9437184 next 26\n",
      "2025-03-30 19:07:55.654756: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a9600a00 of size 2359296 next 62\n",
      "2025-03-30 19:07:55.654766: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a9840a00 of size 2359296 next 64\n",
      "2025-03-30 19:07:55.654776: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a9a80a00 of size 2359296 next 66\n",
      "2025-03-30 19:07:55.654782: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a9cc0a00 of size 2359296 next 39\n",
      "2025-03-30 19:07:55.654787: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883a9f00a00 of size 9437184 next 40\n",
      "2025-03-30 19:07:55.654793: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883aa800a00 of size 9437184 next 42\n",
      "2025-03-30 19:07:55.654799: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883ab100a00 of size 2359296 next 77\n",
      "2025-03-30 19:07:55.654804: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883ab340a00 of size 2359296 next 79\n",
      "2025-03-30 19:07:55.654810: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883ab580a00 of size 2359296 next 81\n",
      "2025-03-30 19:07:55.654816: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883ab7c0a00 of size 2359296 next 55\n",
      "2025-03-30 19:07:55.654821: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883aba00a00 of size 9437184 next 56\n",
      "2025-03-30 19:07:55.654826: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883ac300a00 of size 9437184 next 58\n",
      "2025-03-30 19:07:55.654832: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883acc00a00 of size 9437184 next 71\n",
      "2025-03-30 19:07:55.654838: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883ad500a00 of size 9437184 next 72\n",
      "2025-03-30 19:07:55.654848: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883ade00a00 of size 16512512 next 18446744073709551615\n",
      "2025-03-30 19:07:55.654857: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1094] Next region of size 12039680\n",
      "2025-03-30 19:07:55.654864: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1114] InUse at 7883af200000 of size 12039680 next 18446744073709551615\n",
      "2025-03-30 19:07:55.654873: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119]      Summary of in-use Chunks by size: \n",
      "2025-03-30 19:07:55.654884: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 7 Chunks of size 256 totalling 1.8KiB\n",
      "2025-03-30 19:07:55.654892: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2025-03-30 19:07:55.654903: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 42 Chunks of size 3072 totalling 126.0KiB\n",
      "2025-03-30 19:07:55.654910: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 4 Chunks of size 12288 totalling 48.0KiB\n",
      "2025-03-30 19:07:55.654920: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 19 Chunks of size 2359296 totalling 42.75MiB\n",
      "2025-03-30 19:07:55.654927: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 4715776 totalling 4.50MiB\n",
      "2025-03-30 19:07:55.654936: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 8 Chunks of size 9437184 totalling 72.00MiB\n",
      "2025-03-30 19:07:55.654946: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 12039680 totalling 11.48MiB\n",
      "2025-03-30 19:07:55.654956: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1122] 1 Chunks of size 16512512 totalling 15.75MiB\n",
      "2025-03-30 19:07:55.654966: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1126] Sum Total of in-use chunks: 146.65MiB\n",
      "2025-03-30 19:07:55.654975: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1128] Total bytes in pool: 160675328 memory_limit_: 165150720 available bytes: 4475392 curr_region_allocation_bytes_: 660602880\n",
      "2025-03-30 19:07:55.654992: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1133] Stats: \n",
      "Limit:                       165150720\n",
      "InUse:                       153773312\n",
      "MaxInUse:                    153773312\n",
      "NumAllocs:                         196\n",
      "MaxAllocSize:                 16512512\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2025-03-30 19:07:55.655011: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] *****************************************************************************************xxx*******x\n",
      "2025-03-30 19:07:55.655034: W tensorflow/core/framework/op_kernel.cc:1844] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2025-03-30 19:07:55.655066: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/seb/Desktop/CodingChallenge_MLE/train.py\", line 45, in <module>\n",
      "    model = models.build_model(MAX_LEN)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/seb/Desktop/CodingChallenge_MLE/roberta/models.py\", line 62, in build_model\n",
      "    bert_model = TFRobertaModel.from_pretrained(os.path.join(package_dir, \"config\", \"pretrained-roberta-base.h5\"), config=config)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\", line 2977, in from_pretrained\n",
      "    model.build_in_name_scope()  # build the network with dummy inputs\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/transformers/modeling_tf_utils.py\", line 1197, in build_in_name_scope\n",
      "    self.build(input_shape=None)\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 1060, in build\n",
      "    self.roberta.build(None)\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 865, in build\n",
      "    self.encoder.build(None)\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 660, in build\n",
      "    layer.build(None)\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 575, in build\n",
      "    self.intermediate.build(None)\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_tf_roberta.py\", line 446, in build\n",
      "    self.dense.build([None, None, self.config.hidden_size])\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/layers/core/dense.py\", line 154, in build\n",
      "    self.kernel = self.add_weight(\n",
      "                  ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer.py\", line 705, in add_weight\n",
      "    variable = self._add_variable_with_custom_getter(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/tensorflow/python/trackable/base.py\", line 492, in _add_variable_with_custom_getter\n",
      "    new_variable = getter(\n",
      "                   ^^^^^^^\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/engine/base_layer_utils.py\", line 137, in make_variable\n",
      "    return tf1.Variable(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py\", line 153, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/initializers/initializers.py\", line 525, in __call__\n",
      "    return self._random_generator.truncated_normal(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/seb/python_venvs/general_venv/lib/python3.12/site-packages/tf_keras/src/backend.py\", line 2144, in truncated_normal\n",
      "    return tf.random.stateless_truncated_normal(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: \n"
     ]
    }
   ],
   "source": [
    "!python3 train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <u> Software-Design and Refractoring </u>\n",
    "\n",
    "I turned this into the 'roberta' package. The below classes allow me to be able to write more understandable, and encapulate the functionality in a meaningful way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roberta import RobertaPredictor, TokenEncoder \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalvenvs_ipykernel",
   "language": "python",
   "name": "generalvenvs_ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
